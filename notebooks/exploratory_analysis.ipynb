{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718371d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# ðŸ“Š Sentiment Analysis - Data Exploration\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook explores the dataset, visualizes distributions, and prepares data for modeling.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Objectives:\\n\",\n",
    "    \"- Load and inspect data\\n\",\n",
    "    \"- Visualize sentiment distributions\\n\",\n",
    "    \"- Analyze text statistics\\n\",\n",
    "    \"- Explore word frequencies\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"âœ… Libraries imported successfully\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.data_loader import DataLoader\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize loader\\n\",\n",
    "    \"loader = DataLoader()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load Twitter dataset (or change to IMDB/Amazon)\\n\",\n",
    "    \"df = loader.load_twitter_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nColumns: {df.columns.tolist()}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nFirst few rows:\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Basic Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Dataset info\\n\",\n",
    "    \"print(\\\"Dataset Info:\\\")\\n\",\n",
    "    \"print(f\\\"Total samples: {len(df)}\\\")\\n\",\n",
    "    \"print(f\\\"Missing values: {df.isnull().sum().sum()}\\\")\\n\",\n",
    "    \"print(f\\\"Duplicate rows: {df.duplicated().sum()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sentiment distribution\\n\",\n",
    "    \"print(\\\"\\\\nSentiment Distribution:\\\")\\n\",\n",
    "    \"sentiment_counts = df['sentiment'].value_counts()\\n\",\n",
    "    \"print(sentiment_counts)\\n\",\n",
    "    \"print(f\\\"\\\\nPercentages:\\\")\\n\",\n",
    "    \"print(df['sentiment'].value_counts(normalize=True) * 100)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Visualize Distributions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Bar plot\\n\",\n",
    "    \"sentiment_counts.plot(kind='bar', ax=axes[0], color=['#28a745', '#dc3545', '#ffc107'])\\n\",\n",
    "    \"axes[0].set_title('Sentiment Distribution (Count)', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"axes[0].set_xlabel('Sentiment')\\n\",\n",
    "    \"axes[0].set_ylabel('Count')\\n\",\n",
    "    \"axes[0].tick_params(axis='x', rotation=0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Pie chart\\n\",\n",
    "    \"colors = ['#28a745', '#dc3545', '#ffc107']\\n\",\n",
    "    \"axes[1].pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%',\\n\",\n",
    "    \"            colors=colors, startangle=90)\\n\",\n",
    "    \"axes[1].set_title('Sentiment Distribution (%)', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/visualizations/sentiment_distribution.png', dpi=150, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Text Length Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Calculate text lengths\\n\",\n",
    "    \"df['text_length'] = df['text'].str.len()\\n\",\n",
    "    \"df['word_count'] = df['text'].str.split().str.len()\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(15, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Text length distribution\\n\",\n",
    "    \"df['text_length'].hist(bins=50, ax=axes[0,0], color='skyblue', edgecolor='black')\\n\",\n",
    "    \"axes[0,0].set_title('Distribution of Text Length (Characters)')\\n\",\n",
    "    \"axes[0,0].set_xlabel('Length')\\n\",\n",
    "    \"axes[0,0].set_ylabel('Frequency')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Word count distribution\\n\",\n",
    "    \"df['word_count'].hist(bins=50, ax=axes[0,1], color='lightcoral', edgecolor='black')\\n\",\n",
    "    \"axes[0,1].set_title('Distribution of Word Count')\\n\",\n",
    "    \"axes[0,1].set_xlabel('Word Count')\\n\",\n",
    "    \"axes[0,1].set_ylabel('Frequency')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Box plot by sentiment\\n\",\n",
    "    \"df.boxplot(column='text_length', by='sentiment', ax=axes[1,0])\\n\",\n",
    "    \"axes[1,0].set_title('Text Length by Sentiment')\\n\",\n",
    "    \"axes[1,0].set_xlabel('Sentiment')\\n\",\n",
    "    \"\\n\",\n",
    "    \"df.boxplot(column='word_count', by='sentiment', ax=axes[1,1])\\n\",\n",
    "    \"axes[1,1].set_title('Word Count by Sentiment')\\n\",\n",
    "    \"axes[1,1].set_xlabel('Sentiment')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.suptitle('')  # Remove automatic title\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistics\\n\",\n",
    "    \"print(\\\"Text Length Statistics by Sentiment:\\\")\\n\",\n",
    "    \"print(df.groupby('sentiment')['text_length'].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Word Frequency Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.preprocess import TextPreprocessor\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Preprocess texts\\n\",\n",
    "    \"preprocessor = TextPreprocessor(remove_stopwords=True, lemmatize=True)\\n\",\n",
    "    \"df['processed'] = df['text'].apply(preprocessor.preprocess)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get word frequencies\\n\",\n",
    "    \"all_words = ' '.join(df['processed']).split()\\n\",\n",
    "    \"word_freq = Counter(all_words)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Total words: {len(all_words)}\\\")\\n\",\n",
    "    \"print(f\\\"Unique words: {len(word_freq)}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nTop 20 most common words:\\\")\\n\",\n",
    "    \"for word, count in word_freq.most_common(20):\\n\",\n",
    "    \"    print(f\\\"  {word}: {count}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize top words\\n\",\n",
    "    \"top_words = dict(word_freq.most_common(20))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"plt.bar(top_words.keys(), top_words.values(), color='steelblue')\\n\",\n",
    "    \"plt.title('Top 20 Most Frequent Words', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Words')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/visualizations/top_words.png', dpi=150, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Word Cloud\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from wordcloud import WordCloud\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate word cloud\\n\",\n",
    "    \"wordcloud = WordCloud(width=800, height=400, \\n\",\n",
    "    \"                      background_color='white',\\n\",\n",
    "    \"                      max_words=100).generate(' '.join(df['processed']))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(15, 7))\\n\",\n",
    "    \"plt.imshow(wordcloud, interpolation='bilinear')\\n\",\n",
    "    \"plt.axis('off')\\n\",\n",
    "    \"plt.title('Word Cloud of Processed Text', fontsize=16, fontweight='bold')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/visualizations/wordcloud.png', dpi=150, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Sentiment by Text Length\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create length categories\\n\",\n",
    "    \"df['length_category'] = pd.cut(df['text_length'], \\n\",\n",
    "    \"                               bins=[0, 50, 100, 200, float('inf')],\\n\",\n",
    "    \"                               labels=['Very Short', 'Short', 'Medium', 'Long'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Cross-tabulation\\n\",\n",
    "    \"crosstab = pd.crosstab(df['length_category'], df['sentiment'], normalize='index') * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"crosstab.plot(kind='bar', stacked=True, color=['#28a745', '#dc3545', '#ffc107'])\\n\",\n",
    "    \"plt.title('Sentiment Distribution by Text Length Category', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Length Category')\\n\",\n",
    "    \"plt.ylabel('Percentage')\\n\",\n",
    "    \"plt.legend(title='Sentiment')\\n\",\n",
    "    \"plt.xticks(rotation=0)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nCross-tabulation (counts):\\\")\\n\",\n",
    "    \"print(pd.crosstab(df['length_category'], df['sentiment']))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Save Processed Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save processed dataframe\\n\",\n",
    "    \"output_path = '../data/processed_data.csv'\\n\",\n",
    "    \"df.to_csv(output_path, index=False)\\n\",\n",
    "    \"print(f\\\"âœ… Processed data saved to: {output_path}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Summary\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"DATA EXPLORATION SUMMARY\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(f\\\"Total samples: {len(df)}\\\")\\n\",\n",
    "    \"print(f\\\"Sentiment distribution: {dict(sentiment_counts)}\\\")\\n\",\n",
    "    \"print(f\\\"Average text length: {df['text_length'].mean():.1f} characters\\\")\\n\",\n",
    "    \"print(f\\\"Average word count: {df['word_count'].mean():.1f} words\\\")\\n\",\n",
    "    \"print(f\\\"Vocabulary size: {len(word_freq)} unique words\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
