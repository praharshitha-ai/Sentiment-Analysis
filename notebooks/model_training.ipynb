{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f449b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# ü§ñ Sentiment Analysis - Model Training\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook trains and evaluates multiple ML models for sentiment classification.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Models:\\n\",\n",
    "    \"- Naive Bayes\\n\",\n",
    "    \"- Logistic Regression\\n\",\n",
    "    \"- Support Vector Machine (SVM)\\n\",\n",
    "    \"- Random Forest\\n\",\n",
    "    \"- LSTM (Deep Learning)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, cross_val_score\\n\",\n",
    "    \"from sklearn.metrics import (classification_report, confusion_matrix, \\n\",\n",
    "    \"                            accuracy_score, precision_recall_fscore_support)\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Libraries imported\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Prepare Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.data_loader import DataLoader\\n\",\n",
    "    \"from src.preprocess import TextPreprocessor, download_nltk_data\\n\",\n",
    "    \"from src.features import SimpleFeatureExtractor\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Download NLTK data\\n\",\n",
    "    \"download_nltk_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load data\\n\",\n",
    "    \"loader = DataLoader()\\n\",\n",
    "    \"df = loader.load_twitter_data()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded {len(df)} samples\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Preprocess\\n\",\n",
    "    \"preprocessor = TextPreprocessor(remove_stopwords=True, lemmatize=True)\\n\",\n",
    "    \"df = preprocessor.preprocess_dataframe(df, text_column='text')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract features\\n\",\n",
    "    \"extractor = SimpleFeatureExtractor(method='tfidf', max_features=5000)\\n\",\n",
    "    \"X = extractor.fit_transform(df['processed_text'])\\n\",\n",
    "    \"y = df['sentiment'].values\\n\",\n",
    "    \"\\n\",\n",
    "    print (f\\\"Feature matrix shape: {X.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split data\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=0.2, random_state=42, stratify=y\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Train Traditional ML Models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.models import TraditionalModels\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize models\\n\",\n",
    "    \"models = TraditionalModels()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Naive Bayes\\n\",\n",
    "    \"print(\\\"Training Naive Bayes...\\\")\\n\",\n",
    "    \"nb_model, nb_metrics = models.train_naive_bayes(X_train, y_train, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Logistic Regression\\n\",\n",
    "    \"print(\\\"\\\\nTraining Logistic Regression...\\\")\\n\",\n",
    "    \"lr_model, lr_metrics = models.train_logistic_regression(X_train, y_train, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train SVM\\n\",\n",
    "    \"print(\\\"\\\\nTraining SVM...\\\")\\n\",\n",
    "    \"svm_model, svm_metrics = models.train_svm(X_train, y_train, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Random Forest\\n\",\n",
    "    \"print(\\\"\\\\nTraining Random Forest...\\\")\\n\",\n",
    "    \"rf_model, rf_metrics = models.train_random_forest(X_train, y_train, X_test, y_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Model Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare all models\\n\",\n",
    "    \"models.compare_all()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get best model\\n\",\n",
    "    \"best_name, best_model = models.get_best_model()\\n\",\n",
    "    \"print(f\\\"\\\\nüèÜ Best Model: {best_name}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize comparison\\n\",\n",
    "    \"results_df = pd.DataFrame({\\n\",\n",
    "    \"    'Naive Bayes': [nb_metrics['accuracy'], nb_metrics['precision'], \\n\",\n",
    "    \"                    nb_metrics['recall'], nb_metrics['f1']],\\n\",\n",
    "    \"    'Logistic Regression': [lr_metrics['accuracy'], lr_metrics['precision'],\\n\",\n",
    "    \"                           lr_metrics['recall'], lr_metrics['f1']],\\n\",\n",
    "    \"    'SVM': [svm_metrics['accuracy'], svm_metrics['precision'],\\n\",\n",
    "    \"            svm_metrics['recall'], svm_metrics['f1']],\\n\",\n",
    "    \"    'Random Forest': [rf_metrics['accuracy'], rf_metrics['precision'],\\n\",\n",
    "    \"                     rf_metrics['recall'], rf_metrics['f1']]\\n\",\n",
    "    \"}, index=['Accuracy', 'Precision', 'Recall', 'F1-Score'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_df.plot(kind='bar', figsize=(12, 6))\\n\",\n",
    "    \"plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.ylabel('Score')\\n\",\n",
    "    \"plt.ylim(0, 1)\\n\",\n",
    "    \"plt.legend(loc='lower right')\\n\",\n",
    "    \"plt.xticks(rotation=0)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/visualizations/model_comparison.png', dpi=150)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Detailed Evaluation - Best Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Get predictions from best model\\n\",\n",
    "    \"y_pred = best_model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Classification report\\n\",\n",
    "    \"print(\\\"Classification Report:\\\")\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Confusion matrix\\n\",\n",
    "    \"cm = confusion_matrix(y_test, y_pred)\\n\",\n",
    "    \"plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\\n\",\n",
    "    \"            xticklabels=['negative', 'neutral', 'positive'],\\n\",\n",
    "    \"            yticklabels=['negative', 'neutral', 'positive'])\\n\",\n",
    "    \"plt.title(f'Confusion Matrix - {best_name}', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.ylabel('True Label')\\n\",\n",
    "    \"plt.xlabel('Predicted Label')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/visualizations/confusion_matrix.png', dpi=150)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Cross-Validation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Perform cross-validation\\n\",\n",
    "    \"cv_scores = models.cross_validate(X, y, model_name=best_name, cv=5)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(8, 5))\\n\",\n",
    "    \"plt.bar(range(1, 6), cv_scores, color='steelblue', alpha=0.7)\\n\",\n",
    "    \"plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', \\n\",\n",
    "    \"            label=f'Mean: {cv_scores.mean():.3f}')\\n\",\n",
    "    \"plt.xlabel('Fold')\\n\",\n",
    "    \"plt.ylabel('F1 Score')\\n\",\n",
    "    \"plt.title(f'5-Fold Cross-Validation - {best_name}', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.ylim(0, 1)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"CV Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Train LSTM (Deep Learning)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"tf.config.set_visible_devices([], 'GPU')  # Disable GPU for notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.models import LSTMModel\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare sequences\\n\",\n",
    "    \"lstm = LSTMModel(max_words=5000, max_len=50, embedding_dim=128)\\n\",\n",
    "    \"X_lstm, y_lstm = lstm.prepare_sequences(df['processed_text'], df['sentiment'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split\\n\",\n",
    "    \"X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(\\n\",\n",
    "    \"    X_lstm, y_lstm, test_size=0.2, random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Sequence shape: {X_train_l.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Classes: {lstm.classes}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Build and train LSTM\\n\",\n",
    "    \"lstm.build_model(num_classes=len(lstm.classes), architecture='bidirectional')\\n\",\n",
    "    \"\\n\",\n",
    "    \"history = lstm.train(\\n\",\n",
    "    \"    X_train_l, y_train_l,\\n\",\n",
    "    \"    X_test_l, y_test_l,\\n\",\n",
    "    \"    epochs=10,\\n\",\n",
    "    \"    batch_size=32\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot training history\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Accuracy\\n\",\n",
    "    \"axes[0].plot(history.history['accuracy'], label='Train')\\n\",\n",
    "    \"axes[0].plot(history.history['val_accuracy'], label='Validation')\\n\",\n",
    "    \"axes[0].set_title('Model Accuracy')\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Accuracy')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Loss\\n\",\n",
    "    \"axes[1].plot(history.history['loss'], label='Train')\\n\",\n",
    "    \"axes[1].plot(history.history['val_loss'], label='Validation')\\n\",\n",
    "    \"axes[1].set_title('Model Loss')\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Loss')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/visualizations/lstm_training.png', dpi=150)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate LSTM\\n\",\n",
    "    \"lstm_metrics = lstm.evaluate(X_test_l, y_test_l)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Compare with traditional models\\n\",\n",
    "    \"comparison = pd.DataFrame({\\n\",\n",
    "    \"    'Traditional ML (Best)': [lr_metrics['accuracy'], lr_metrics['f1']],\\n\",\n",
    "    '    'LSTM Deep Learning': [lstm_metrics['accuracy'], \\n\",\n",
    "    \"                          2 * (lstm_metrics['precision'] * lstm_metrics['recall']) / \\n\",\n",
    "    \"                          (lstm_metrics['precision'] + lstm_metrics['recall'])]\\n\",\n",
    "    \"}, index=['Accuracy', 'F1-Score'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison.plot(kind='bar', figsize=(8, 5))\\n\",\n",
    "    \"plt.title('Traditional ML vs Deep Learning', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.ylabel('Score')\\n\",\n",
    "    \"plt.ylim(0, 1)\\n\",\n",
    "    \"plt.xticks(rotation=0)\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(comparison)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Save Models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pickle\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create models directory\\n\",\n",
    "    \"os.makedirs('../models', exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save best traditional model\\n\",\n",
    "    \"with open(f'../models/{best_name}.pkl', 'wb') as f:\\n\",\n",
    "    \"    pickle.dump(best_model, f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save preprocessor and extractor\\n\",\n",
    "    \"with open('../models/preprocessor.pkl', 'wb') as f:\\n\",\n",
    "    \"    pickle.dump(preprocessor, f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"extractor.save('../models/feature_extractor.pkl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save LSTM\\n\",\n",
    "    \"lstm.save('../models/lstm_model.h5', '../models/lstm_tokenizer.pkl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ All models saved!\\\")\\n\",\n",
    "    \"print(\\\"\\\\nSaved files:\\\")\\n\",\n",
    "    \"for f in os.listdir('../models'):\\n\",\n",
    "    \"    print(f\\\"  - {f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Summary\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"TRAINING SUMMARY\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    print(f\\\"Best Traditional Model: {best_name}\\\")\\n\",\n",
    "    \"print(f\\\"  Accuracy:  {lr_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  F1-Score:  {lr_metrics['f1']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nLSTM Deep Learning:\\\")\\n\",\n",
    "    \"print(f\\\"  Accuracy:  {lstm_metrics['accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Precision: {lstm_metrics['precision']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"  Recall:    {lstm_metrics['recall']:.4f}\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e83f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
